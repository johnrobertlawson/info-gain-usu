{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T21:41:27.418006Z",
     "start_time": "2024-02-09T21:41:27.412274Z"
    }
   },
   "id": "2676604d334eb86a",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class DivergenceScore:\n",
    "    def __init__(self,df=None):\n",
    "        \"\"\"\n",
    "        o, f    :   1-D series of observations and forecasts\n",
    "        \"\"\"      \n",
    "        self.df = df\n",
    "        self.N = np.sum(self.df.nk)\n",
    "        self.pks = np.array([self.df.pk])\n",
    "        \n",
    "        self.eps = self._determine_eps(None)\n",
    "        self.base = 2\n",
    "        self.log = self._determine_log(self.base)\n",
    "        self.ks = self.df.columns\n",
    "        \n",
    "    @staticmethod\n",
    "    def _determine_log(base):\n",
    "        if base == 2:\n",
    "            return np.log2\n",
    "        elif base == \"e\":\n",
    "            return np.log \n",
    "        elif base == 10:\n",
    "            return np.log10\n",
    "        else:\n",
    "            raise Exception(\"Choose log base from 2, 10, or e\")\n",
    "        \n",
    "    @classmethod\n",
    "    def compute_dkl(cls,q,p,base,eps=None):\n",
    "        eps = cls._determine_eps(eps)\n",
    "        log = cls._determine_log(base)\n",
    "        dkl = q*log(q/(p+eps)) + (1-q)*log((1-q)/(1-p+eps))\n",
    "        return dkl\n",
    "    \n",
    "    @staticmethod\n",
    "    def _determine_eps(eps):\n",
    "        if eps is None:\n",
    "            return np.finfo(float).eps\n",
    "        else:\n",
    "            assert eps > np.finfo(float).eps\n",
    "            return eps\n",
    "    \n",
    "    @classmethod\n",
    "    def compute_ds_from_components(cls,rel=None,res=None,unc=None):\n",
    "        assert rel and res and unc \n",
    "        return unc - res + rel \n",
    "    \n",
    "    def compute_ds(self,from_components=False,return_all=False):\n",
    "        if from_components:\n",
    "            rel = self.compute_rel()\n",
    "            res = self.compute_res()\n",
    "            unc = self.compute_unc()\n",
    "            if return_all:\n",
    "                print(\"Note that return_all is ignored outputting components\")\n",
    "            return self.compute_ds_from_components(rel=rel,res=res,unc=unc)\n",
    "        else:\n",
    "            try:\n",
    "                ds_series = self.compute_dkl(self.o,self.f, self.base)\n",
    "            except AttributeError:\n",
    "                # or \"if self.o is None\"\n",
    "                print(\"You can only ask for DS computed from a time series.\")\n",
    "            if return_all:\n",
    "                return ds_series\n",
    "            return np.mean(ds_series)\n",
    "        \n",
    "    def compute_rel(self):\n",
    "        total_dkl = 0\n",
    "        for i, k in enumerate(self.ks):   \n",
    "            ok_bar = self.df.loc[\"ok\",k]/self.df.loc[\"nk\",k]\n",
    "            dkl = self.compute_dkl(ok_bar,self.df.loc[\"pk\",k],self.base)\n",
    "            total_dkl += dkl * self.df.loc[\"nk\",k]\n",
    "        return total_dkl/self.N\n",
    "    \n",
    "    def compute_res(self):\n",
    "        total_dkl = 0\n",
    "        for i, k in enumerate(self.ks):   \n",
    "            ok_bar = self.df.loc[\"ok\",k]/self.df.loc[\"nk\",k]\n",
    "            o_bar = np.sum(self.df.loc[\"ok\"])/self.N\n",
    "            dkl = self.compute_dkl(ok_bar,o_bar,base=self.base)\n",
    "            total_dkl += dkl * self.df.loc[\"nk\",k]\n",
    "            # print(i,k,ok_bar,o_bar,dkl,total_dkl)\n",
    "        return total_dkl/self.N\n",
    "    \n",
    "    def compute_unc(self):\n",
    "        o_bar = self.eps + np.sum(self.df.loc[\"ok\"])/self.N\n",
    "        unc = -(o_bar * self.log(o_bar) + (1-o_bar) * self.log(1-o_bar)) \n",
    "        return unc \n",
    "\n",
    "        \n",
    "        "
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-09T21:42:40.734611Z",
     "start_time": "2024-02-09T21:42:40.726947Z"
    }
   },
   "id": "initial_id",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T21:42:15.560968Z",
     "start_time": "2024-02-09T21:42:15.557665Z"
    }
   },
   "id": "84d6b6ae0a6e7c56",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total observations (sum of ok): 43911\n",
      "Total forecasts (sum of nk): 43911\n"
     ]
    },
    {
     "data": {
      "text/plain": "      pk     ok    nk\n0   0.01  11070  9350\n1   0.05   5535  7756\n2   0.10   6642  7903\n3   0.20   6642  7048\n4   0.30   4428  2806\n5   0.40   1845  1168\n6   0.50   1722   928\n7   0.60   1968  2597\n8   0.70   2214  2355\n9   0.80    984  1148\n10  0.90    369   185\n11  0.95    246   350\n12  0.99    246   317",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pk</th>\n      <th>ok</th>\n      <th>nk</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.01</td>\n      <td>11070</td>\n      <td>9350</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.05</td>\n      <td>5535</td>\n      <td>7756</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.10</td>\n      <td>6642</td>\n      <td>7903</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.20</td>\n      <td>6642</td>\n      <td>7048</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.30</td>\n      <td>4428</td>\n      <td>2806</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.40</td>\n      <td>1845</td>\n      <td>1168</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.50</td>\n      <td>1722</td>\n      <td>928</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.60</td>\n      <td>1968</td>\n      <td>2597</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>0.70</td>\n      <td>2214</td>\n      <td>2355</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.80</td>\n      <td>984</td>\n      <td>1148</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>0.90</td>\n      <td>369</td>\n      <td>185</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>0.95</td>\n      <td>246</td>\n      <td>350</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.99</td>\n      <td>246</td>\n      <td>317</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Given parameters\n",
    "probability_bins = np.array([0.01, 0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99])\n",
    "observations = np.array([90, 45, 54, 54, 36, 15, 14, 16, 18, 8, 3, 2, 2]) * 123\n",
    "\n",
    "# Step 1: Add more variation to nk\n",
    "# Generate random variation factors with a larger range to increase variability\n",
    "np.random.seed(42)  # For reproducibility\n",
    "random_variation = np.random.uniform(0.5, 1.5, size=len(probability_bins))\n",
    "\n",
    "# Adjust nk with added variation and ensure integers\n",
    "nk = np.round(observations * random_variation).astype(int)\n",
    "\n",
    "# Step 2: Ensure the sum of ok and nk are the same\n",
    "total_ok = np.sum(observations)\n",
    "total_nk = np.sum(nk)\n",
    "\n",
    "# If total_nk is different from total_ok, adjust nk values proportionally\n",
    "if total_nk != total_ok:\n",
    "    adjustment_ratio = total_ok / total_nk\n",
    "    nk = np.round(nk * adjustment_ratio).astype(int)\n",
    "\n",
    "    # Fine-tune to ensure exact match in totals due to rounding\n",
    "    while np.sum(nk) != total_ok:\n",
    "        difference = total_ok - np.sum(nk)\n",
    "        indices = np.random.choice(range(len(nk)), abs(difference), replace=True)\n",
    "        for i in indices:\n",
    "            nk[i] += np.sign(difference)\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "forecast_df = pd.DataFrame({\n",
    "    'pk': probability_bins,\n",
    "    'ok': observations,\n",
    "    'nk': nk,\n",
    "})\n",
    "\n",
    "print(f\"Total observations (sum of ok): {np.sum(observations)}\")\n",
    "print(f\"Total forecasts (sum of nk): {np.sum(nk)}\")\n",
    "forecast_df\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T21:42:15.918334Z",
     "start_time": "2024-02-09T21:42:15.914827Z"
    }
   },
   "id": "67381e1e353edf0e",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pk'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m div_score \u001B[38;5;241m=\u001B[39m DivergenceScore(df\u001B[38;5;241m=\u001B[39mforecast_df)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Compute and print REL, RES, UNC, DKL, and DSS\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m rel \u001B[38;5;241m=\u001B[39m \u001B[43mdiv_score\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute_rel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m res \u001B[38;5;241m=\u001B[39m div_score\u001B[38;5;241m.\u001B[39mcompute_res()\n\u001B[1;32m      7\u001B[0m unc \u001B[38;5;241m=\u001B[39m div_score\u001B[38;5;241m.\u001B[39mcompute_unc()\n",
      "Cell \u001B[0;32mIn[10], line 67\u001B[0m, in \u001B[0;36mDivergenceScore.compute_rel\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     65\u001B[0m total_dkl \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, k \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mks):   \n\u001B[0;32m---> 67\u001B[0m     ok_bar \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mok\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m/\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf\u001B[38;5;241m.\u001B[39mloc[k,\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnk\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m     68\u001B[0m     dkl \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_dkl(ok_bar,\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf\u001B[38;5;241m.\u001B[39mloc[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpk\u001B[39m\u001B[38;5;124m\"\u001B[39m,k],\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbase)\n\u001B[1;32m     69\u001B[0m     total_dkl \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m dkl \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf\u001B[38;5;241m.\u001B[39mloc[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnk\u001B[39m\u001B[38;5;124m\"\u001B[39m,k]\n",
      "File \u001B[0;32m~/anaconda3/envs/infogain63/lib/python3.11/site-packages/pandas/core/indexing.py:1146\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   1144\u001B[0m     key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(com\u001B[38;5;241m.\u001B[39mapply_if_callable(x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m key)\n\u001B[1;32m   1145\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_scalar_access(key):\n\u001B[0;32m-> 1146\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtakeable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_takeable\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_tuple(key)\n\u001B[1;32m   1148\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1149\u001B[0m     \u001B[38;5;66;03m# we by definition only have the 0th axis\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/infogain63/lib/python3.11/site-packages/pandas/core/frame.py:4015\u001B[0m, in \u001B[0;36mDataFrame._get_value\u001B[0;34m(self, index, col, takeable)\u001B[0m\n\u001B[1;32m   4009\u001B[0m engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39m_engine\n\u001B[1;32m   4011\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex, MultiIndex):\n\u001B[1;32m   4012\u001B[0m     \u001B[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001B[39;00m\n\u001B[1;32m   4013\u001B[0m     \u001B[38;5;66;03m#  results if our categories are integers that dont match our codes\u001B[39;00m\n\u001B[1;32m   4014\u001B[0m     \u001B[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001B[39;00m\n\u001B[0;32m-> 4015\u001B[0m     row \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4016\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m series\u001B[38;5;241m.\u001B[39m_values[row]\n\u001B[1;32m   4018\u001B[0m \u001B[38;5;66;03m# For MultiIndex going through engine effectively restricts us to\u001B[39;00m\n\u001B[1;32m   4019\u001B[0m \u001B[38;5;66;03m#  same-length tuples; see test_get_set_value_no_partial_indexing\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/infogain63/lib/python3.11/site-packages/pandas/core/indexes/range.py:418\u001B[0m, in \u001B[0;36mRangeIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m    416\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Hashable):\n\u001B[0;32m--> 418\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n\u001B[1;32m    419\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n\u001B[1;32m    420\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'pk'"
     ]
    }
   ],
   "source": [
    "# Initialize DivergenceScore object\n",
    "div_score = DivergenceScore(df=forecast_df)\n",
    "\n",
    "# Compute and print REL, RES, UNC, DKL, and DSS\n",
    "rel = div_score.compute_rel()\n",
    "res = div_score.compute_res()\n",
    "unc = div_score.compute_unc()\n",
    "ds = div_score.compute_ds(from_components=True)\n",
    "dss = div_score.compute_ds()  \n",
    "\n",
    "print(f\"REL: {rel}, RES: {res}, UNC: {unc}, DKL: {ds}\")\n",
    "\n",
    "# Create a DataFrame to store these metrics for visualization\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Metric': ['REL', 'RES', 'UNC', 'DKL'],\n",
    "    'Value': [rel, res, unc, ds]\n",
    "})\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-09T21:42:44.815671Z",
     "start_time": "2024-02-09T21:42:44.774958Z"
    }
   },
   "id": "27781f80a94228de",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Bar plot for REL, RES, UNC, and DKL\n",
    "sns.barplot(x='Metric', y='Value', data=metrics_df)\n",
    "plt.title('Forecast Metrics')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-09T21:41:28.000830Z"
    }
   },
   "id": "674dcb76d037c6f9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
